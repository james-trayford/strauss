{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b8078ed-f15d-4974-921f-76bd3dd1abc1",
   "metadata": {},
   "source": [
    "#### Preamble for `CoLab` "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7bed847-f2d1-4d63-8014-578a1ae02be9",
   "metadata": {},
   "source": [
    "To use this notebook (if you haven't already) you can first save a copy to your local drive by clicking `File > Save a Copy in Drive` and run on that copy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f39f554-2a47-4b21-9535-dee61be097a3",
   "metadata": {},
   "source": [
    "_Note_: `Colab` is a really handy way to test and try `strauss`, though it will generally run and display audio more slowly than running on your local machine. For a more responsive experience, why not install `strauss` locally, following the instructions [on the Github](https://github.com/james-trayford/strauss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f0e0b3-3902-4987-bc12-6c3b34b813c4",
   "metadata": {},
   "source": [
    "Run these cells, so that the notebook functions on the _Google_ `Colab` platform:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decb1419-76fe-4460-b75b-cc4d8fdeda64",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip --quiet install strauss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570dac35-219e-41d1-8361-87b3b8799e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/james-trayford/strauss.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42fa0ab-0f1e-4617-b2b1-16f7bdafe038",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd strauss/examples/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b73a45",
   "metadata": {},
   "source": [
    "## <u> Demonstrate `Spectraliser` Generator type to represent Data:</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f21355",
   "metadata": {},
   "source": [
    "**First, import relevant modules:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64e736a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload \n",
    "%autoreload 2\n",
    "import matplotlib.pyplot as plt\n",
    "from strauss.sonification import Sonification\n",
    "from strauss.sources import Events, Objects\n",
    "from strauss import channels\n",
    "from strauss.score import Score\n",
    "from strauss.generator import Spectralizer\n",
    "import IPython.display as ipd\n",
    "import os\n",
    "from scipy.interpolate import interp1d\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a3e9c2-e9e3-48ca-a21c-0ae64bb549f6",
   "metadata": {},
   "source": [
    "In other examples we use a 'parameter mapping' approach for one-dimensional data series, where we map _y_ as a function of _x_ using the change in some expressive property of sound (e.g. `pitch_shift`) as a function of time.\n",
    "\n",
    "We consider a direct spectralisation approach where the sopund is generated by treating th 1D data as a sound spectrum! This uses a direct inverse Fourier transform.This seems relatively intuitive for spectral data, particular those with spectral features similar to what we can identify in sound.\n",
    "\n",
    "We will use Planetary Nebulae (PNe) data to demonstrate this, objects that are dominated by strong emission lines..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f82b67-f083-4028-b931-9d615c642113",
   "metadata": {},
   "source": [
    "**First, let's grab some data...**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf7b1b5-79b7-4a2a-a8e9-15f196a15ca6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spectral_data1 = np.genfromtxt('../data/datasets/NGC1535.csv', delimiter=',')\n",
    "wlen1 = spectral_data1[:,0]\n",
    "fluxdens1 = spectral_data1[:,1]\n",
    "\n",
    "spectral_data2 = np.genfromtxt('../data/datasets/NGC6302.csv', delimiter=',')\n",
    "wlen2 = spectral_data2[:,0]\n",
    "fluxdens2 = spectral_data2[:,1]\n",
    "\n",
    "# spectrum needs to be provided to the Spectraliser in frequency order (i.e. low to high), \n",
    "# so we ensure it is sorted that way... \n",
    "spec1 = fluxdens1[np.argsort(1/wlen1)]\n",
    "spec2 = fluxdens2[np.argsort(1/wlen2)]\n",
    "wlen1 = wlen1[np.argsort(1/wlen1)]\n",
    "wlen2 = wlen2[np.argsort(1/wlen2)]\n",
    "\n",
    "# plot the spectra vs wavlength\n",
    "plt.plot(wlen1, spec1/spec1.max(), label= 'NGC1535')\n",
    "plt.plot(wlen2, spec2/spec2.max(), alpha=0.6, label= 'NGC6302')\n",
    "plt.xlabel('Wavelength [Angstrom]')\n",
    "plt.ylabel('Flux')\n",
    "plt.legend(frameon=False)\n",
    "plt.show()\n",
    "\n",
    "# plot the spectra vs frequency\n",
    "plt.plot(1e-12*3e8/(wlen1*1e-10), spec1/spec1.max(),label= 'NGC1535')\n",
    "plt.plot(1e-12*3e8/(wlen2*1e-10), spec2/spec2.max(), alpha=0.6,label= 'NGC1535')\n",
    "plt.xlabel('Frequency [THz]')\n",
    "plt.ylabel('Flux')\n",
    "plt.legend(frameon=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f6edf6-59bf-4bdc-a9e7-c7f097cd08d3",
   "metadata": {},
   "source": [
    "**Set up some universal sonification parameters and classes for the examples below**\n",
    "\n",
    "For all examples we use the `Synthesizer` generator to create a 30 second, mono sonification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009d6c9a-fb4c-4cd9-a87d-ccae4f280d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify audio system (e.g. mono, stereo, 5.1, ...)\n",
    "system = \"stereo\"\n",
    "\n",
    "# length of the sonification in s\n",
    "length = 10."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a7b7ed-6da8-4694-8aef-df00a7277d42",
   "metadata": {},
   "source": [
    "### <u>Example 1</u> &nbsp; **Comparing the NGC 1535 & NGC 6302 Spectra**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198556fa-7913-440a-81da-256abb047a22",
   "metadata": {},
   "source": [
    "Lets compare the _Spectraliser_ representations of these two spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c92480b-345a-4212-883c-b9eded4060d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "notes = [[\"A2\"]]\n",
    "\n",
    "score =  Score(notes, length)\n",
    "\n",
    "spectra = [spec1, spec2]\n",
    "wlens = [wlen1, wlen2]\n",
    "names = ['NGC 1535', 'NGC 6302']\n",
    "\n",
    "for i in range(2):\n",
    "\n",
    "    #set up spectralizer generator\n",
    "    generator = Spectralizer()\n",
    "\n",
    "    # Lets pick the mapping frequency range for the spectrum...\n",
    "    generator.modify_preset({'min_freq':100, 'max_freq':1000})\n",
    "\n",
    "    s = np.zeros(spec1.size)\n",
    "    s[-1] = 1\n",
    "    # set up spectrum and choose some envelope parameters for fade-in and fade-out\n",
    "    data = {'spectrum':[spectra[i]], 'pitch':[1],\n",
    "            'volume_envelope/D':[0.9], \n",
    "            'volume_envelope/S':[0.], \n",
    "            'volume_envelope/A':[0.05]}\n",
    "    \n",
    "    # again, use maximal range for the mapped parameters\n",
    "    lims = {'spectrum': ('0','100')}\n",
    "    \n",
    "    # set up source\n",
    "    sources = Events(data.keys())\n",
    "    sources.fromdict(data)\n",
    "    sources.apply_mapping_functions(map_lims=lims)\n",
    "    \n",
    "    # render and play sonification!\n",
    "    soni = Sonification(score, sources, generator, system)\n",
    "    soni.render()\n",
    "    print(f\"Spectralising {names[i]}...\")\n",
    "    plt.plot(1e-12*3e8/(wlens[i]*1e-10), spectra[i]/spectra[i].max(), alpha=0.7,label=names[i])\n",
    "    soni.notebook_display(show_waveform=0)\n",
    "plt.xlabel('Frequency [THz]')\n",
    "plt.ylabel('Flux')\n",
    "plt.legend(frameon=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285b12a8-ef64-49f9-a851-b011bde05e29",
   "metadata": {},
   "source": [
    "What differences do you notice about the sounds? Can you here the presence/absence of spectral lines, and their relative pitches?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f17dd1-fe8c-4b61-8a15-4a3cedb646b4",
   "metadata": {},
   "source": [
    "### <u>Example 2</u> &nbsp; **Evolving Spectra and Image Sonification**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61b32e0-2dfb-40b9-ab94-6e4c2516208d",
   "metadata": {},
   "source": [
    "We could also perform a `Object` type sonification with an evolving Spectrum. \n",
    "\n",
    "An evolving spectrum can be represented as a 2D array, similar to a regular image. Using this similarity, the `Spectraliser` provides a neat way to sonify images!\n",
    "\n",
    "Here we sonify the `strauss` logo, lets grab it..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1efde9b-c4c9-4c0f-b4c5-9d32a2098fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = plt.imread('../misc/strauss_logo.png')\n",
    "image = image[:,:,:-1].sum(axis=-1)\n",
    "image_inv = 1-image\n",
    "plt.imshow(image_inv, cmap='gray_r')\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad7df5b-6bab-476c-8100-a7b251403b85",
   "metadata": {},
   "source": [
    "in `strauss` each row represents a spectrum, ordered from first to last.\n",
    "\n",
    "Convention to represent the image is to evolve from left to right, with higher features in the _y_-axis sounding higher pitch. Due to image formatting conventions being different, we need transpse and flip the image array to get the right format for `strauss`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b225242-fbea-46ff-8b86-020e9c7b11bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_stack = image_inv[::-1].T\n",
    "plt.imshow(spec_stack,  cmap='gray_r')\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e2e482-41fb-4bb1-bac8-80a4c5dafd54",
   "metadata": {},
   "source": [
    "Now let's _Spectralise_!  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a583f3bd-b57b-4448-8cf2-d30de234a3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#show the image again...\n",
    "plt.imshow(image_inv, cmap='gray_r')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "score =  Score(notes, 15)\n",
    "\n",
    "#set up spectralizer generator\n",
    "generator = Spectralizer()\n",
    "\n",
    "# Lets pick the mapping frequency range for the spectrum...\n",
    "generator.modify_preset({'min_freq':20, 'max_freq':10000})\n",
    "\n",
    "# set up spectrum\n",
    "data = {'spectrum':[spec_stack], 'pitch':[1]}\n",
    "\n",
    "# again, use maximal range for the mapped parameters\n",
    "lims = {'spectrum': ('0','100')}\n",
    "\n",
    "# set up source\n",
    "sources = Events(data.keys())\n",
    "sources.fromdict(data)\n",
    "sources.apply_mapping_functions(map_lims=lims)\n",
    "\n",
    "# render and play sonification!\n",
    "soni = Sonification(score, sources, generator, system)\n",
    "soni.render()\n",
    "print(f\"Spectralising Image...\")\n",
    "soni.notebook_display(show_waveform=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
