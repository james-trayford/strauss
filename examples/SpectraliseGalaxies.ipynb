{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03b73a45",
   "metadata": {},
   "source": [
    "## <u> Convert some spectrum to an audio spectrum and generate the sound</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f21355",
   "metadata": {},
   "source": [
    "First, we import relevant modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64e736a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload \n",
    "%autoreload 2\n",
    "import matplotlib.pyplot as plt\n",
    "import ffmpeg as ff\n",
    "import wavio as wav\n",
    "from strauss.sonification import Sonification\n",
    "from strauss.sources import Events\n",
    "from strauss import channels\n",
    "from strauss.score import Score\n",
    "import numpy as np\n",
    "from strauss.generator import Sampler, Synthesizer\n",
    "import IPython.display as ipd\n",
    "from IPython.core.display import display\n",
    "import os\n",
    "from scipy.signal import savgol_filter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db324dd0-d627-41c7-b13a-538b35921502",
   "metadata": {},
   "source": [
    "### Discrete wavelengths: A first example with emission line galaxies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7abfdcc-73b4-4086-b276-eadad642ce1f",
   "metadata": {},
   "source": [
    "As a first example, we choose some discrete wavelengths to sonify, representing emission lines from the galaxy **NGC1569** (or optionally **NGC4670**, commented out). [Example spectrum can be seen here](http://astronomy.nmsu.edu/nicole/teaching/ASTR505/lectures/lecture26/pics/Irr.gif). Here the frequencies are in nanometers (nm). The strenth of these lines above the *continuum* is mapped to the volume of these frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b499f966-798d-47a2-8089-4935cbbe6509",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "wlens = [372, 386, 410, 433, 485, 495, \n",
    "         500, 587, 630, 640, 654, 655, \n",
    "         658, 671]\n",
    "\n",
    "#NGC1569\n",
    "vols  = [3.21, 1.38, 1.09, 1.86, 5.54, 9.2,\n",
    "         26.77, 1.51, 1.30, 1.13, 3.00, 21.72, \n",
    "         1.91, 2.64]\n",
    "\n",
    "#NGC4670\n",
    "#vols  = [21.07, 1.67, 1.54, 3.7, 9.22, 7.31,\n",
    "#         21.8, 0.61, 0.65, 0.00, 8.97, 21.84, 2.35,\n",
    "#         3.17]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63b79c5-bd70-42fb-8c52-7e3cc8bfa665",
   "metadata": {},
   "source": [
    "The frequencies volume of each line is mapped from `'0'`-`'100'` where strings indicate the percentile range. For volum numerical `0` implies zero amplitude, and `'100'` is the 100th percentile, i.e. the volume of the strongest line (here the oxygen OIII line, at 500nm)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd6ea24-324b-4309-9004-651a4a1e7e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "maplims =  {'pitch' : ('0', '100'),\n",
    "            'volume' : (-0.5, '100')}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b109ba0-72d1-4775-a224-11386ffc4f19",
   "metadata": {},
   "source": [
    "We then convert the light ***wavelengths*** to sound ***frequencies***. While we want all these frequences to be in the audible range (~20-20,000 Hz) this mapping is somewhat arbitrary. What's the best range to use for this example?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15ef66f-5b49-486f-b946-87f3f51c7b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the maximum and minimum sound frequency we use to map our tones... what happens if we change this?\n",
    "FMAX = 3000\n",
    "FMIN = 100\n",
    "\n",
    "freqs = (1/np.array(wlens))\n",
    "# Start at 5 Hz\n",
    "freqs *= (FMAX-FMIN)/(freqs.max()-freqs.min())\n",
    "freqs += FMIN-freqs.min()\n",
    "\n",
    "# make sure pitches are ordered from lowest to highest frequency\n",
    "chords=[freqs[::-1]]\n",
    "print(chords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77f4bde-c5b6-4336-b5a3-b68e208d2d93",
   "metadata": {},
   "source": [
    "We are now ready to set up the sonification! \n",
    "\n",
    "We load the special preset `'spectraliser'` which will generate the tones we want. We decide on a length and system for the simulation (make it short for quicker generation, using `mono` only generates a single channel so also speeds things up as we don't need stereo information for this example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c86ca8-d36d-4b9f-ac6f-a6826f77b538",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Synthesizer()\n",
    "generator.load_preset('spectraliser')\n",
    "length = \"0m 4s\"\n",
    "system='mono'\n",
    "score =  Score(chords, length)\n",
    "\n",
    "# higher pitch -> higher *frequency* (not wavelength)\n",
    "ps = np.array(freqs)\n",
    "vs = np.array(vols)\n",
    "\n",
    "events = Events(['pitch', 'volume'])\n",
    "events.raw_mapping = dict(zip(['pitch', 'volume'],\n",
    "                           [ps, vs]))\n",
    "\n",
    "events.apply_mapping_functions(map_lims=maplims)\n",
    "events.n_sources = ps.shape[0]\n",
    "soni = Sonification(score, events, generator, system)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a226fbcf-427b-4e45-8910-62f31ccb511f",
   "metadata": {},
   "source": [
    "We render the sonification..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7ef182-745d-4d08-96b7-74af17fbc421",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "soni.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217b93f2-690b-4d3c-9126-d5b0609bdcc5",
   "metadata": {},
   "source": [
    "Then display and listen to it, also plotting the spectral lines showing the 'partials' that constitute the sound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd65931-3417-4386-8f0e-39408c435499",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "soni.notebook_display()\n",
    "plt.vlines(ps, vs*0, vs)\n",
    "plt.ylim(0,30)\n",
    "plt.semilogx()\n",
    "plt.xlabel('Pitch Frequency (Hz)')\n",
    "plt.ylabel('Amplitude')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3348ee1-2b10-4120-acf7-ecddbfc78cc3",
   "metadata": {},
   "source": [
    "and save the WAV file if you like (as e.g. `some/path/file.wav`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e418cedf-c8ed-42b1-85b5-e1d8e99f4969",
   "metadata": {},
   "outputs": [],
   "source": [
    "soni.save(FILEPATH_AS_A_STRING.WAV)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7b9259-e72e-47b0-866a-3fd503daf9bc",
   "metadata": {},
   "source": [
    "### Continuous wavelengths: A full stellar spectrum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17dd0b3-c17b-44ca-95ce-afa73674f38a",
   "metadata": {},
   "source": [
    "We can extend this approach to render a continuous spectrum using a grid of wavelengths. First we can load the example M-class stellar spectrum (or O-class by changing the filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e0cf77-a032-4e3f-8239-cffb9c823200",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('../data/datasets/M_spectrum.txt')\n",
    "volumes = data[:,1]\n",
    "wlens   = data[:,0]\n",
    "\n",
    "# A different maximum and minimum sound frequency this time... what happens if we change this?\n",
    "FMAX = 10000\n",
    "FMIN = 50\n",
    "freqs = (1/np.array(wlens))\n",
    "freqs *= (FMAX-FMIN)/(freqs.max()-freqs.min())\n",
    "freqs += FMIN-freqs.min()\n",
    "\n",
    "# make sure pitches are ordered from lowest to highest frequency\n",
    "chords=[freqs[::-1]]\n",
    "print(chords)\n",
    "\n",
    "plt.plot(freqs, volumes)\n",
    "plt.semilogx()\n",
    "plt.xlabel('Pitch Frequency (Hz)')\n",
    "plt.ylabel('Amplitude')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c929be4-fb09-4859-b77a-f0e889614245",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# smooth the spectrum, this will give something like the continuum\n",
    "volumes_smooth = savgol_filter(volumes, 51, 3)\n",
    "\n",
    "# subtracting away the 'continuum' \n",
    "volumes_negfeats = -np.clip((volumes - volumes_smooth), -np.inf, 0)#/volumes_smooth_O\n",
    "volumes_posfeats = np.clip((volumes - volumes_smooth), 0, np.inf)#/volumes_smooth_O\n",
    "\n",
    "plt.plot(freqs, volumes, c='k', alpha=0.3)\n",
    "plt.plot(freqs, volumes_smooth - 0.6*volumes_O.max())\n",
    "plt.plot(freqs, volumes_negfeats - 1.2*volumes_O.max())\n",
    "plt.plot(freqs, volumes_posfeats - 1.8*volumes_O.max())\n",
    "plt.semilogx()\n",
    "plt.xlabel('Pitch Frequency (Hz)')\n",
    "plt.ylabel('Amplitude')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa9357c-133e-4828-8f8b-97fa589faaf0",
   "metadata": {},
   "source": [
    "Same mapping limits as the first example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442c2213-3f9d-4db8-8786-dc55410ee465",
   "metadata": {},
   "outputs": [],
   "source": [
    "maplims =  {'pitch' : ('0', '100'),\n",
    "            'volume' : (0, '100')}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d517cd7c-46a2-40a1-9428-4b7c0462836a",
   "metadata": {},
   "source": [
    "Setup sonification generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61cc582a-48b5-43f7-b76e-ca6a0db008a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "generator = Synthesizer()\n",
    "generator.load_preset('spectraliser')\n",
    "length = \"0m 4s\"\n",
    "system='mono'\n",
    "score =  Score(chords, length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1906be0-f92f-4751-a949-882a3926e2a5",
   "metadata": {},
   "source": [
    "As an aside, one feature of the spectraliser preset is that the phases of the different frequencies are randomised, using the special keyword `'random'`, this can also just be set to e.g. a constant value so that all the pitches have the same phases. This value is from 0-1 and represents the fraction of a sine-wave's cycle that the tones start on. I wonder why this is set to random, and what happens if we change the phase to a constant value (e.g. `0`)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79739e0-935d-47ce-a45a-73863e79923f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Phase setting before: \", generator.preset['oscillators']['osc1']['phase'])\n",
    "generator.modify_preset({'oscillators':{'osc1':{'phase':'random'}}})\n",
    "print(\"Phase setting after: \", generator.preset['oscillators']['osc1']['phase'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d9ffef-85d1-469a-8261-32208f9b498e",
   "metadata": {},
   "source": [
    "Now setup the sonification again, choosing one of the 'volumes' to use..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ace2a30-7e4c-4e6c-9e9a-72cf96d00105",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# higher pitch -> higher *frequency* (not wavelength)\n",
    "ps = np.array(freqs)\n",
    "\n",
    "# listen to the negative features (absorption) by default, can change this\n",
    "vs = np.array(volumes_negfeats)\n",
    "\n",
    "events = Events(['pitch', 'volume'])\n",
    "events.raw_mapping = dict(zip(['pitch', 'volume'],\n",
    "                           [ps, vs]))\n",
    "\n",
    "events.apply_mapping_functions(map_lims=maplims)\n",
    "events.n_sources = ps.shape[0]\n",
    "soni2 = Sonification(score, events, generator, system)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b568ba0-64c5-4871-a6d9-291422752632",
   "metadata": {},
   "source": [
    "...and render (this will take longer as we are using many more frequencies, remember the shorter the sonification the quicker the render)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def981df-7075-4dd7-9e53-7dcf78863714",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "soni2.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f6a087-7b3b-4fec-92b6-2779f2dc70be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "soni2.notebook_display()\n",
    "plt.plot(ps,vs)\n",
    "plt.semilogx()\n",
    "plt.xlabel('Pitch Frequency (Hz)')\n",
    "plt.ylabel('Amplitude')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d018cb-33e2-408e-b0bd-09452611effd",
   "metadata": {},
   "source": [
    "and save the WAV file if you like (as e.g. `some/path/file.wav`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cc070d-10f7-4be9-86b3-5ab5d2f72023",
   "metadata": {},
   "outputs": [],
   "source": [
    "soni2.save(FILEPATH_AS_A_STRING.WAV)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a295dc-7215-4328-91a7-a9e44e221e45",
   "metadata": {},
   "source": [
    "As a bonus, what if we generated some simple functions to sonify as spectra?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a52db9-43ef-4331-8f14-1e518cc6b0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "vol_flat = np.ones(freqs.shape)\n",
    "vol_single = (freqs == FMIN).astype(float)\n",
    "vol_shallow = (freqs/5000)**-0.5\n",
    "vol_steep = (freqs/5000)**-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ed1b14-65b9-40f6-bb77-c403ec3dd38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# higher pitch -> higher *frequency* (not wavelength)\n",
    "ps = np.array(freqs)\n",
    "\n",
    "# listen to vol_steep by default\n",
    "vs = np.array(vol_steep)\n",
    "\n",
    "events = Events(['pitch', 'volume'])\n",
    "events.raw_mapping = dict(zip(['pitch', 'volume'],\n",
    "                           [ps, vs]))\n",
    "\n",
    "events.apply_mapping_functions(map_lims=maplims)\n",
    "events.n_sources = ps.shape[0]\n",
    "soni3 = Sonification(score, events, generator, system)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5903ed13-28b3-4c91-b8b0-cd64fbd47f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "soni3.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd031a3-166d-4d8f-9ddc-1eba6ee79f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "soni3.notebook_display()\n",
    "plt.plot(ps,vs)\n",
    "plt.semilogx()\n",
    "plt.xlabel('Pitch Frequency (Hz)')\n",
    "plt.ylabel('Amplitude')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3773773-8b79-46b6-806a-3d7616431274",
   "metadata": {},
   "source": [
    "and save the WAV file if you like (as e.g. `some/path/file.wav`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a1eba5-393a-4b0b-bb74-02fa98eced33",
   "metadata": {},
   "outputs": [],
   "source": [
    "soni3.save(FILEPATH_AS_A_STRING.WAV)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
